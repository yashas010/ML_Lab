{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFogxfy_0HPa",
        "outputId": "b6907df5-97e7-48bf-d732-0bcdc82064c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RBF Kernel MSE: 0.2510\n",
            "Polynomial Kernel MSE: 0.1928\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate random 2D data\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(20, 2)\n",
        "Y = np.sin(X[:, 0] * 10) + np.cos(X[:, 1] * 5)\n",
        "Y = Y.reshape(-1, 1)\n",
        "\n",
        "# --- Kernel Functions ---\n",
        "def rbf_kernel(x1, x2, sigma=1.0):\n",
        "    return np.exp(-np.linalg.norm(x1 - x2) ** 2 / (2 * (sigma ** 2)))\n",
        "\n",
        "def poly_kernel(x1, x2, degree=3, coef0=1):\n",
        "    return (np.dot(x1, x2.T) + coef0) ** degree\n",
        "\n",
        "# --- RBF Network Setup ---\n",
        "kmeans = KMeans(n_clusters=6, n_init=10).fit(X)\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "d_max = np.max(cdist(centers, centers))\n",
        "sigma = d_max / np.sqrt(2 * len(centers))\n",
        "\n",
        "def build_kernel_matrix(X, centers, kernel_func, **kwargs):\n",
        "    K = np.zeros((X.shape[0], len(centers)))\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(len(centers)):\n",
        "            K[i, j] = kernel_func(X[i], centers[j], **kwargs)\n",
        "    return K\n",
        "\n",
        "# RBF Model\n",
        "R_rbf = build_kernel_matrix(X, centers, rbf_kernel, sigma=sigma)\n",
        "W_rbf = np.dot(np.linalg.pinv(R_rbf), Y)\n",
        "y_pred_rbf = np.dot(R_rbf, W_rbf)\n",
        "mse_rbf = mean_squared_error(Y, y_pred_rbf)\n",
        "\n",
        "# Polynomial Kernel Model\n",
        "R_poly = build_kernel_matrix(X, centers, poly_kernel, degree=3, coef0=1)\n",
        "W_poly = np.dot(np.linalg.pinv(R_poly), Y)\n",
        "y_pred_poly = np.dot(R_poly, W_poly)\n",
        "mse_poly = mean_squared_error(Y, y_pred_poly)\n",
        "\n",
        "print(f\"RBF Kernel MSE: {mse_rbf:.4f}\")\n",
        "print(f\"Polynomial Kernel MSE: {mse_poly:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Kernel Function        | MSE    | Observation                                                                                    |\n",
        "| ---------------------- | ------ | ---------------------------------------------------------------------------------------------- |\n",
        "| **RBF (Gaussian)**     | 0.2510 | Performs well, capturing localized non-linear patterns. Slight underfitting seen.              |\n",
        "| **Polynomial (deg=3)** | 0.1928 | Performs better here, likely due to mild global trends in random data. Shows more flexibility. |\n",
        "\n",
        " Conclusion:\n",
        "- Although RBF is known for precise modeling of local relationships, in this case, Polynomial kernel surprisingly achieved a lower MSE, indicating it fit the generated random data slightly better.\n",
        "\n",
        "\n",
        "- This highlights the importance of trying multiple kernels and validating with error metrics like MSE."
      ],
      "metadata": {
        "id": "M2A0hln00isx"
      }
    }
  ]
}